{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VanillaRNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shipra-bhadauria/Deep-Learning_practice/blob/main/VanillaRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "380EOpqIkyOr"
      },
      "source": [
        "\n",
        "-----------Problem Statement---------------------\n",
        "\n",
        "Reuters Newswire Topic Classification Dataset. \n",
        "\n",
        "It consists of 11,228 newswires from Reuters classified into 46 main topics.\n",
        "Features  is a list of sequences which represents the newswire text.\n",
        "\n",
        "Labels is a list of integer labels from 1 to 90 which represents different categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH91phA4koVi"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import reuters\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Activation\n",
        "from keras import optimizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFRJwgjXlNxx"
      },
      "source": [
        "# parameters for data load\n",
        "## num_worsds: top most frequent words to consider;\n",
        "## maxlen= maximum sequence lengths to be considered, truncate long sequences.\n",
        "num_words = 30000\n",
        "maxlen = 50\n",
        "test_split = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI-fN53ZlWg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd7eda7-9071-45ae-e0c5-ee8d9aa08f90"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n",
            "(1395,)\n",
            "(1395,)\n",
            "(599,)\n",
            "(599,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/reuters.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/reuters.py:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlVEhlQHll_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab72fb8f-b1b0-44ca-84f4-89750fb7adbd"
      },
      "source": [
        "#pad_sequences transform a list into a 2D array\n",
        "# pad the sequences with zeros \n",
        "# padding parameter is set to 'post' => 0's are appended to end of sequences\n",
        "X_train = pad_sequences(X_train, padding = 'post')\n",
        "X_test = pad_sequences(X_test, padding = 'post')\n",
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  245,  273,  207,  156,   53,   74,  160,   26,   14,   46,\n",
              "        296,   26,   39,   74, 2979, 3554,   14,   46, 4689, 4329,   86,\n",
              "         61, 3499, 4795,   14,   61,  451, 4329,   17,   12,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyFABbcgmTm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3f1962-6140-409f-ae94-f6e0492ac381"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1395, 49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZuvZ5ZXmB74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359b4524-a9c2-4f52-8f25-5a66aca15617"
      },
      "source": [
        "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1395, 49, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNRPMJXHmhr9"
      },
      "source": [
        "y_data = np.concatenate((y_train, y_test))\n",
        "y_data = to_categorical(y_data)\n",
        "y_train = y_data[:1395]\n",
        "y_test = y_data[1395:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBXC4qQ1Jr9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7378474-bd68-4fb5-e37b-71da2eca64b9"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1395, 46)\n",
            "(599, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBFeQUyK51D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51604686-96ea-457b-dc8e-25794569e57f"
      },
      "source": [
        "y_data[1,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGHxiMDZmohR"
      },
      "source": [
        "def vanilla_rnn():\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(30, input_shape = (49,1), return_sequences = False, dropout=0.2))\n",
        "    model.add(Dense(46)) #output layer \n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    adam = optimizers.Adam(lr = 0.001)\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndazzZrbmwTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8607f040-fd32-47e1-84c7-ca13bf84349c"
      },
      "source": [
        "model = KerasClassifier(build_fn = vanilla_rnn, epochs = 200, batch_size = 50, verbose = 1,validation_data=(X_test,y_test))\n",
        "history=model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 3.6047 - accuracy: 0.3441 - val_loss: 3.1438 - val_accuracy: 0.6144\n",
            "Epoch 2/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 2.5394 - accuracy: 0.6444 - val_loss: 1.8821 - val_accuracy: 0.7028\n",
            "Epoch 3/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.6049 - accuracy: 0.6796 - val_loss: 1.3069 - val_accuracy: 0.7229\n",
            "Epoch 4/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.3060 - accuracy: 0.6918 - val_loss: 1.1965 - val_accuracy: 0.7229\n",
            "Epoch 5/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.2307 - accuracy: 0.7032 - val_loss: 1.1677 - val_accuracy: 0.7479\n",
            "Epoch 6/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.2002 - accuracy: 0.7133 - val_loss: 1.1566 - val_accuracy: 0.7479\n",
            "Epoch 7/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1879 - accuracy: 0.7140 - val_loss: 1.1506 - val_accuracy: 0.7479\n",
            "Epoch 8/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1811 - accuracy: 0.7147 - val_loss: 1.1420 - val_accuracy: 0.7479\n",
            "Epoch 9/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1704 - accuracy: 0.7147 - val_loss: 1.1426 - val_accuracy: 0.7479\n",
            "Epoch 10/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1644 - accuracy: 0.7147 - val_loss: 1.1381 - val_accuracy: 0.7479\n",
            "Epoch 11/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1624 - accuracy: 0.7147 - val_loss: 1.1409 - val_accuracy: 0.7479\n",
            "Epoch 12/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1610 - accuracy: 0.7147 - val_loss: 1.1403 - val_accuracy: 0.7479\n",
            "Epoch 13/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1596 - accuracy: 0.7147 - val_loss: 1.1446 - val_accuracy: 0.7479\n",
            "Epoch 14/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1584 - accuracy: 0.7147 - val_loss: 1.1431 - val_accuracy: 0.7479\n",
            "Epoch 15/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1565 - accuracy: 0.7147 - val_loss: 1.1463 - val_accuracy: 0.7479\n",
            "Epoch 16/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1563 - accuracy: 0.7147 - val_loss: 1.1449 - val_accuracy: 0.7479\n",
            "Epoch 17/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1559 - accuracy: 0.7147 - val_loss: 1.1465 - val_accuracy: 0.7479\n",
            "Epoch 18/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.1552 - accuracy: 0.7147 - val_loss: 1.1492 - val_accuracy: 0.7479\n",
            "Epoch 19/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1543 - accuracy: 0.7147 - val_loss: 1.1457 - val_accuracy: 0.7479\n",
            "Epoch 20/200\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 1.1549 - accuracy: 0.7147 - val_loss: 1.1458 - val_accuracy: 0.7479\n",
            "Epoch 21/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1527 - accuracy: 0.7147 - val_loss: 1.1488 - val_accuracy: 0.7479\n",
            "Epoch 22/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.1542 - accuracy: 0.7147 - val_loss: 1.1468 - val_accuracy: 0.7479\n",
            "Epoch 23/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.1519 - accuracy: 0.7147 - val_loss: 1.1466 - val_accuracy: 0.7479\n",
            "Epoch 24/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1530 - accuracy: 0.7147 - val_loss: 1.1472 - val_accuracy: 0.7479\n",
            "Epoch 25/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1510 - accuracy: 0.7147 - val_loss: 1.1510 - val_accuracy: 0.7479\n",
            "Epoch 26/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1523 - accuracy: 0.7147 - val_loss: 1.1441 - val_accuracy: 0.7479\n",
            "Epoch 27/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1509 - accuracy: 0.7147 - val_loss: 1.1492 - val_accuracy: 0.7479\n",
            "Epoch 28/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1511 - accuracy: 0.7147 - val_loss: 1.1455 - val_accuracy: 0.7479\n",
            "Epoch 29/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1521 - accuracy: 0.7147 - val_loss: 1.1496 - val_accuracy: 0.7479\n",
            "Epoch 30/200\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 1.1499 - accuracy: 0.7147 - val_loss: 1.1435 - val_accuracy: 0.7479\n",
            "Epoch 31/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1506 - accuracy: 0.7147 - val_loss: 1.1457 - val_accuracy: 0.7479\n",
            "Epoch 32/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1496 - accuracy: 0.7147 - val_loss: 1.1482 - val_accuracy: 0.7479\n",
            "Epoch 33/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.1495 - accuracy: 0.7147 - val_loss: 1.1458 - val_accuracy: 0.7479\n",
            "Epoch 34/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1494 - accuracy: 0.7147 - val_loss: 1.1456 - val_accuracy: 0.7479\n",
            "Epoch 35/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1470 - accuracy: 0.7147 - val_loss: 1.1454 - val_accuracy: 0.7479\n",
            "Epoch 36/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1468 - accuracy: 0.7147 - val_loss: 1.1439 - val_accuracy: 0.7479\n",
            "Epoch 37/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1489 - accuracy: 0.7147 - val_loss: 1.1428 - val_accuracy: 0.7479\n",
            "Epoch 38/200\n",
            "28/28 [==============================] - 1s 44ms/step - loss: 1.1452 - accuracy: 0.7147 - val_loss: 1.1432 - val_accuracy: 0.7479\n",
            "Epoch 39/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1463 - accuracy: 0.7147 - val_loss: 1.1457 - val_accuracy: 0.7479\n",
            "Epoch 40/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.1449 - accuracy: 0.7147 - val_loss: 1.1435 - val_accuracy: 0.7479\n",
            "Epoch 41/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1458 - accuracy: 0.7147 - val_loss: 1.1451 - val_accuracy: 0.7479\n",
            "Epoch 42/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.1477 - accuracy: 0.7147 - val_loss: 1.1445 - val_accuracy: 0.7479\n",
            "Epoch 43/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1448 - accuracy: 0.7147 - val_loss: 1.1437 - val_accuracy: 0.7479\n",
            "Epoch 44/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1481 - accuracy: 0.7147 - val_loss: 1.1461 - val_accuracy: 0.7479\n",
            "Epoch 45/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.1479 - accuracy: 0.7147 - val_loss: 1.1423 - val_accuracy: 0.7479\n",
            "Epoch 46/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.1461 - accuracy: 0.7147 - val_loss: 1.1433 - val_accuracy: 0.7479\n",
            "Epoch 47/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1456 - accuracy: 0.7147 - val_loss: 1.1465 - val_accuracy: 0.7479\n",
            "Epoch 48/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1460 - accuracy: 0.7147 - val_loss: 1.1424 - val_accuracy: 0.7479\n",
            "Epoch 49/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1451 - accuracy: 0.7147 - val_loss: 1.1460 - val_accuracy: 0.7479\n",
            "Epoch 50/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1429 - accuracy: 0.7147 - val_loss: 1.1444 - val_accuracy: 0.7479\n",
            "Epoch 51/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1432 - accuracy: 0.7147 - val_loss: 1.1426 - val_accuracy: 0.7479\n",
            "Epoch 52/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1452 - accuracy: 0.7147 - val_loss: 1.1487 - val_accuracy: 0.7479\n",
            "Epoch 53/200\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 1.1441 - accuracy: 0.7147 - val_loss: 1.1416 - val_accuracy: 0.7479\n",
            "Epoch 54/200\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 1.1438 - accuracy: 0.7147 - val_loss: 1.1428 - val_accuracy: 0.7479\n",
            "Epoch 55/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.1455 - accuracy: 0.7147 - val_loss: 1.1465 - val_accuracy: 0.7479\n",
            "Epoch 56/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1469 - accuracy: 0.7147 - val_loss: 1.1447 - val_accuracy: 0.7479\n",
            "Epoch 57/200\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 1.1434 - accuracy: 0.7147 - val_loss: 1.1458 - val_accuracy: 0.7479\n",
            "Epoch 58/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1439 - accuracy: 0.7147 - val_loss: 1.1478 - val_accuracy: 0.7479\n",
            "Epoch 59/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.1452 - accuracy: 0.7147 - val_loss: 1.1443 - val_accuracy: 0.7479\n",
            "Epoch 60/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.1435 - accuracy: 0.7147 - val_loss: 1.1447 - val_accuracy: 0.7479\n",
            "Epoch 61/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1454 - accuracy: 0.7147 - val_loss: 1.1420 - val_accuracy: 0.7479\n",
            "Epoch 62/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1449 - accuracy: 0.7147 - val_loss: 1.1419 - val_accuracy: 0.7479\n",
            "Epoch 63/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1431 - accuracy: 0.7147 - val_loss: 1.1453 - val_accuracy: 0.7479\n",
            "Epoch 64/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.1426 - accuracy: 0.7147 - val_loss: 1.1479 - val_accuracy: 0.7479\n",
            "Epoch 65/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.1424 - accuracy: 0.7147 - val_loss: 1.1441 - val_accuracy: 0.7479\n",
            "Epoch 66/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1444 - accuracy: 0.7147 - val_loss: 1.1460 - val_accuracy: 0.7479\n",
            "Epoch 67/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1427 - accuracy: 0.7147 - val_loss: 1.1459 - val_accuracy: 0.7479\n",
            "Epoch 68/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1397 - accuracy: 0.7147 - val_loss: 1.1465 - val_accuracy: 0.7479\n",
            "Epoch 69/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.1421 - accuracy: 0.7147 - val_loss: 1.1465 - val_accuracy: 0.7479\n",
            "Epoch 70/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1440 - accuracy: 0.7147 - val_loss: 1.1462 - val_accuracy: 0.7479\n",
            "Epoch 71/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1408 - accuracy: 0.7147 - val_loss: 1.1503 - val_accuracy: 0.7479\n",
            "Epoch 72/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1400 - accuracy: 0.7147 - val_loss: 1.1504 - val_accuracy: 0.7479\n",
            "Epoch 73/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1414 - accuracy: 0.7147 - val_loss: 1.1465 - val_accuracy: 0.7479\n",
            "Epoch 74/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1402 - accuracy: 0.7147 - val_loss: 1.1528 - val_accuracy: 0.7479\n",
            "Epoch 75/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1430 - accuracy: 0.7147 - val_loss: 1.1459 - val_accuracy: 0.7479\n",
            "Epoch 76/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1384 - accuracy: 0.7147 - val_loss: 1.1482 - val_accuracy: 0.7479\n",
            "Epoch 77/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1414 - accuracy: 0.7147 - val_loss: 1.1460 - val_accuracy: 0.7479\n",
            "Epoch 78/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1412 - accuracy: 0.7147 - val_loss: 1.1461 - val_accuracy: 0.7479\n",
            "Epoch 79/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.1378 - accuracy: 0.7147 - val_loss: 1.1459 - val_accuracy: 0.7479\n",
            "Epoch 80/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1386 - accuracy: 0.7147 - val_loss: 1.1519 - val_accuracy: 0.7479\n",
            "Epoch 81/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1356 - accuracy: 0.7147 - val_loss: 1.1436 - val_accuracy: 0.7479\n",
            "Epoch 82/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.1327 - accuracy: 0.7147 - val_loss: 1.1402 - val_accuracy: 0.7479\n",
            "Epoch 83/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.1359 - accuracy: 0.7147 - val_loss: 1.1399 - val_accuracy: 0.7479\n",
            "Epoch 84/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.1286 - accuracy: 0.7147 - val_loss: 1.1496 - val_accuracy: 0.7479\n",
            "Epoch 85/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.1195 - accuracy: 0.7147 - val_loss: 1.1976 - val_accuracy: 0.7479\n",
            "Epoch 86/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.1267 - accuracy: 0.7147 - val_loss: 1.1409 - val_accuracy: 0.7479\n",
            "Epoch 87/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.1257 - accuracy: 0.7147 - val_loss: 1.1684 - val_accuracy: 0.7479\n",
            "Epoch 88/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.1176 - accuracy: 0.7147 - val_loss: 1.1292 - val_accuracy: 0.7479\n",
            "Epoch 89/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1181 - accuracy: 0.7147 - val_loss: 1.1315 - val_accuracy: 0.7479\n",
            "Epoch 90/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1152 - accuracy: 0.7147 - val_loss: 1.1299 - val_accuracy: 0.7479\n",
            "Epoch 91/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0979 - accuracy: 0.7147 - val_loss: 1.1190 - val_accuracy: 0.7479\n",
            "Epoch 92/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0917 - accuracy: 0.7147 - val_loss: 1.1166 - val_accuracy: 0.7479\n",
            "Epoch 93/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.1281 - accuracy: 0.7147 - val_loss: 1.1114 - val_accuracy: 0.7479\n",
            "Epoch 94/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.0940 - accuracy: 0.7147 - val_loss: 1.1136 - val_accuracy: 0.7479\n",
            "Epoch 95/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.1065 - accuracy: 0.7147 - val_loss: 1.1167 - val_accuracy: 0.7479\n",
            "Epoch 96/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0916 - accuracy: 0.7147 - val_loss: 1.1290 - val_accuracy: 0.7479\n",
            "Epoch 97/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0911 - accuracy: 0.7147 - val_loss: 1.1087 - val_accuracy: 0.7479\n",
            "Epoch 98/200\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 1.0836 - accuracy: 0.7147 - val_loss: 1.1008 - val_accuracy: 0.7479\n",
            "Epoch 99/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0854 - accuracy: 0.7147 - val_loss: 1.1237 - val_accuracy: 0.7479\n",
            "Epoch 100/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.1003 - accuracy: 0.7147 - val_loss: 1.1098 - val_accuracy: 0.7462\n",
            "Epoch 101/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0768 - accuracy: 0.7147 - val_loss: 1.1151 - val_accuracy: 0.7479\n",
            "Epoch 102/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.0784 - accuracy: 0.7147 - val_loss: 1.1021 - val_accuracy: 0.7479\n",
            "Epoch 103/200\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 1.0809 - accuracy: 0.7147 - val_loss: 1.0958 - val_accuracy: 0.7479\n",
            "Epoch 104/200\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 1.0877 - accuracy: 0.7147 - val_loss: 1.1004 - val_accuracy: 0.7462\n",
            "Epoch 105/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.0912 - accuracy: 0.7147 - val_loss: 1.1205 - val_accuracy: 0.7479\n",
            "Epoch 106/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0871 - accuracy: 0.7154 - val_loss: 1.1104 - val_accuracy: 0.7462\n",
            "Epoch 107/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0748 - accuracy: 0.7140 - val_loss: 1.1154 - val_accuracy: 0.7462\n",
            "Epoch 108/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0718 - accuracy: 0.7140 - val_loss: 1.1069 - val_accuracy: 0.7479\n",
            "Epoch 109/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0700 - accuracy: 0.7147 - val_loss: 1.1013 - val_accuracy: 0.7462\n",
            "Epoch 110/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0641 - accuracy: 0.7147 - val_loss: 1.1040 - val_accuracy: 0.7462\n",
            "Epoch 111/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0680 - accuracy: 0.7147 - val_loss: 1.1027 - val_accuracy: 0.7462\n",
            "Epoch 112/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0814 - accuracy: 0.7140 - val_loss: 1.0998 - val_accuracy: 0.7462\n",
            "Epoch 113/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0649 - accuracy: 0.7140 - val_loss: 1.0954 - val_accuracy: 0.7462\n",
            "Epoch 114/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0572 - accuracy: 0.7154 - val_loss: 1.0991 - val_accuracy: 0.7462\n",
            "Epoch 115/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0697 - accuracy: 0.7161 - val_loss: 1.0906 - val_accuracy: 0.7462\n",
            "Epoch 116/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0586 - accuracy: 0.7133 - val_loss: 1.0928 - val_accuracy: 0.7462\n",
            "Epoch 117/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.0599 - accuracy: 0.7140 - val_loss: 1.0968 - val_accuracy: 0.7462\n",
            "Epoch 118/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0522 - accuracy: 0.7147 - val_loss: 1.0924 - val_accuracy: 0.7462\n",
            "Epoch 119/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0547 - accuracy: 0.7140 - val_loss: 1.0774 - val_accuracy: 0.7479\n",
            "Epoch 120/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0530 - accuracy: 0.7147 - val_loss: 1.0818 - val_accuracy: 0.7462\n",
            "Epoch 121/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0463 - accuracy: 0.7154 - val_loss: 1.0843 - val_accuracy: 0.7462\n",
            "Epoch 122/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0647 - accuracy: 0.7104 - val_loss: 1.0843 - val_accuracy: 0.7462\n",
            "Epoch 123/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0383 - accuracy: 0.7168 - val_loss: 1.0752 - val_accuracy: 0.7462\n",
            "Epoch 124/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0541 - accuracy: 0.7140 - val_loss: 1.0844 - val_accuracy: 0.7462\n",
            "Epoch 125/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0449 - accuracy: 0.7168 - val_loss: 1.0745 - val_accuracy: 0.7462\n",
            "Epoch 126/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0462 - accuracy: 0.7168 - val_loss: 1.0842 - val_accuracy: 0.7462\n",
            "Epoch 127/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0383 - accuracy: 0.7140 - val_loss: 1.0999 - val_accuracy: 0.7479\n",
            "Epoch 128/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0615 - accuracy: 0.7125 - val_loss: 1.0872 - val_accuracy: 0.7446\n",
            "Epoch 129/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0414 - accuracy: 0.7140 - val_loss: 1.0935 - val_accuracy: 0.7462\n",
            "Epoch 130/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0560 - accuracy: 0.7147 - val_loss: 1.0749 - val_accuracy: 0.7462\n",
            "Epoch 131/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0419 - accuracy: 0.7140 - val_loss: 1.0826 - val_accuracy: 0.7462\n",
            "Epoch 132/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0451 - accuracy: 0.7154 - val_loss: 1.0929 - val_accuracy: 0.7462\n",
            "Epoch 133/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0404 - accuracy: 0.7154 - val_loss: 1.0849 - val_accuracy: 0.7462\n",
            "Epoch 134/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0421 - accuracy: 0.7140 - val_loss: 1.0836 - val_accuracy: 0.7462\n",
            "Epoch 135/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0406 - accuracy: 0.7125 - val_loss: 1.0816 - val_accuracy: 0.7462\n",
            "Epoch 136/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0332 - accuracy: 0.7154 - val_loss: 1.0765 - val_accuracy: 0.7462\n",
            "Epoch 137/200\n",
            "28/28 [==============================] - 1s 43ms/step - loss: 1.0342 - accuracy: 0.7154 - val_loss: 1.0970 - val_accuracy: 0.7462\n",
            "Epoch 138/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.0431 - accuracy: 0.7118 - val_loss: 1.0922 - val_accuracy: 0.7446\n",
            "Epoch 139/200\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 1.0365 - accuracy: 0.7118 - val_loss: 1.0780 - val_accuracy: 0.7462\n",
            "Epoch 140/200\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 1.0256 - accuracy: 0.7154 - val_loss: 1.0852 - val_accuracy: 0.7462\n",
            "Epoch 141/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.0337 - accuracy: 0.7111 - val_loss: 1.0808 - val_accuracy: 0.7462\n",
            "Epoch 142/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.0203 - accuracy: 0.7104 - val_loss: 1.0877 - val_accuracy: 0.7462\n",
            "Epoch 143/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.0268 - accuracy: 0.7161 - val_loss: 1.0907 - val_accuracy: 0.7462\n",
            "Epoch 144/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.0355 - accuracy: 0.7140 - val_loss: 1.0660 - val_accuracy: 0.7462\n",
            "Epoch 145/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.0206 - accuracy: 0.7154 - val_loss: 1.0765 - val_accuracy: 0.7462\n",
            "Epoch 146/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.0371 - accuracy: 0.7161 - val_loss: 1.0845 - val_accuracy: 0.7462\n",
            "Epoch 147/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.0193 - accuracy: 0.7197 - val_loss: 1.0824 - val_accuracy: 0.7462\n",
            "Epoch 148/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0283 - accuracy: 0.7154 - val_loss: 1.0777 - val_accuracy: 0.7446\n",
            "Epoch 149/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0297 - accuracy: 0.7147 - val_loss: 1.0834 - val_accuracy: 0.7462\n",
            "Epoch 150/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0254 - accuracy: 0.7154 - val_loss: 1.0754 - val_accuracy: 0.7462\n",
            "Epoch 151/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.0203 - accuracy: 0.7147 - val_loss: 1.0741 - val_accuracy: 0.7462\n",
            "Epoch 152/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0145 - accuracy: 0.7154 - val_loss: 1.0725 - val_accuracy: 0.7462\n",
            "Epoch 153/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.0211 - accuracy: 0.7147 - val_loss: 1.0697 - val_accuracy: 0.7462\n",
            "Epoch 154/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.0172 - accuracy: 0.7140 - val_loss: 1.0813 - val_accuracy: 0.7429\n",
            "Epoch 155/200\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 1.0259 - accuracy: 0.7147 - val_loss: 1.0775 - val_accuracy: 0.7462\n",
            "Epoch 156/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0160 - accuracy: 0.7118 - val_loss: 1.0715 - val_accuracy: 0.7462\n",
            "Epoch 157/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0198 - accuracy: 0.7140 - val_loss: 1.0724 - val_accuracy: 0.7462\n",
            "Epoch 158/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0125 - accuracy: 0.7140 - val_loss: 1.0724 - val_accuracy: 0.7462\n",
            "Epoch 159/200\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 1.0193 - accuracy: 0.7097 - val_loss: 1.0804 - val_accuracy: 0.7462\n",
            "Epoch 160/200\n",
            "28/28 [==============================] - 1s 42ms/step - loss: 1.0148 - accuracy: 0.7204 - val_loss: 1.0926 - val_accuracy: 0.7446\n",
            "Epoch 161/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0252 - accuracy: 0.7168 - val_loss: 1.0824 - val_accuracy: 0.7462\n",
            "Epoch 162/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0205 - accuracy: 0.7140 - val_loss: 1.0913 - val_accuracy: 0.7429\n",
            "Epoch 163/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0150 - accuracy: 0.7147 - val_loss: 1.0873 - val_accuracy: 0.7462\n",
            "Epoch 164/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0236 - accuracy: 0.7125 - val_loss: 1.1206 - val_accuracy: 0.7462\n",
            "Epoch 165/200\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 1.0259 - accuracy: 0.7133 - val_loss: 1.0878 - val_accuracy: 0.7462\n",
            "Epoch 166/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0182 - accuracy: 0.7147 - val_loss: 1.0805 - val_accuracy: 0.7462\n",
            "Epoch 167/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0035 - accuracy: 0.7140 - val_loss: 1.0760 - val_accuracy: 0.7462\n",
            "Epoch 168/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0193 - accuracy: 0.7118 - val_loss: 1.0882 - val_accuracy: 0.7462\n",
            "Epoch 169/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0126 - accuracy: 0.7111 - val_loss: 1.0852 - val_accuracy: 0.7479\n",
            "Epoch 170/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0120 - accuracy: 0.7104 - val_loss: 1.1102 - val_accuracy: 0.7462\n",
            "Epoch 171/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0161 - accuracy: 0.7176 - val_loss: 1.0879 - val_accuracy: 0.7462\n",
            "Epoch 172/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0134 - accuracy: 0.7125 - val_loss: 1.0718 - val_accuracy: 0.7462\n",
            "Epoch 173/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.0110 - accuracy: 0.7125 - val_loss: 1.0851 - val_accuracy: 0.7479\n",
            "Epoch 174/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0094 - accuracy: 0.7118 - val_loss: 1.0759 - val_accuracy: 0.7462\n",
            "Epoch 175/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0139 - accuracy: 0.7154 - val_loss: 1.0764 - val_accuracy: 0.7462\n",
            "Epoch 176/200\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 1.0209 - accuracy: 0.7133 - val_loss: 1.1038 - val_accuracy: 0.7429\n",
            "Epoch 177/200\n",
            "28/28 [==============================] - 1s 44ms/step - loss: 1.0118 - accuracy: 0.7140 - val_loss: 1.0863 - val_accuracy: 0.7462\n",
            "Epoch 178/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0139 - accuracy: 0.7133 - val_loss: 1.0922 - val_accuracy: 0.7462\n",
            "Epoch 179/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0177 - accuracy: 0.7147 - val_loss: 1.0905 - val_accuracy: 0.7462\n",
            "Epoch 180/200\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 1.0059 - accuracy: 0.7176 - val_loss: 1.0877 - val_accuracy: 0.7462\n",
            "Epoch 181/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0104 - accuracy: 0.7140 - val_loss: 1.0736 - val_accuracy: 0.7446\n",
            "Epoch 182/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0051 - accuracy: 0.7125 - val_loss: 1.1241 - val_accuracy: 0.7446\n",
            "Epoch 183/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0161 - accuracy: 0.7154 - val_loss: 1.0888 - val_accuracy: 0.7446\n",
            "Epoch 184/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0083 - accuracy: 0.7111 - val_loss: 1.0910 - val_accuracy: 0.7479\n",
            "Epoch 185/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0112 - accuracy: 0.7147 - val_loss: 1.0945 - val_accuracy: 0.7479\n",
            "Epoch 186/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0055 - accuracy: 0.7176 - val_loss: 1.0964 - val_accuracy: 0.7462\n",
            "Epoch 187/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0126 - accuracy: 0.7168 - val_loss: 1.0920 - val_accuracy: 0.7462\n",
            "Epoch 188/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0145 - accuracy: 0.7118 - val_loss: 1.0898 - val_accuracy: 0.7462\n",
            "Epoch 189/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 1.0149 - accuracy: 0.7168 - val_loss: 1.0848 - val_accuracy: 0.7462\n",
            "Epoch 190/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 0.9945 - accuracy: 0.7147 - val_loss: 1.0853 - val_accuracy: 0.7462\n",
            "Epoch 191/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 1.0117 - accuracy: 0.7104 - val_loss: 1.0925 - val_accuracy: 0.7446\n",
            "Epoch 192/200\n",
            "28/28 [==============================] - 1s 36ms/step - loss: 1.0127 - accuracy: 0.7118 - val_loss: 1.0904 - val_accuracy: 0.7479\n",
            "Epoch 193/200\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 1.0013 - accuracy: 0.7211 - val_loss: 1.0907 - val_accuracy: 0.7429\n",
            "Epoch 194/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.0076 - accuracy: 0.7147 - val_loss: 1.0786 - val_accuracy: 0.7479\n",
            "Epoch 195/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 0.9995 - accuracy: 0.7161 - val_loss: 1.0979 - val_accuracy: 0.7462\n",
            "Epoch 196/200\n",
            "28/28 [==============================] - 1s 39ms/step - loss: 1.0002 - accuracy: 0.7147 - val_loss: 1.0898 - val_accuracy: 0.7429\n",
            "Epoch 197/200\n",
            "28/28 [==============================] - 1s 34ms/step - loss: 0.9990 - accuracy: 0.7133 - val_loss: 1.0988 - val_accuracy: 0.7446\n",
            "Epoch 198/200\n",
            "28/28 [==============================] - 1s 33ms/step - loss: 0.9942 - accuracy: 0.7154 - val_loss: 1.0938 - val_accuracy: 0.7396\n",
            "Epoch 199/200\n",
            "28/28 [==============================] - 1s 40ms/step - loss: 1.0031 - accuracy: 0.7247 - val_loss: 1.1129 - val_accuracy: 0.7429\n",
            "Epoch 200/200\n",
            "28/28 [==============================] - 1s 37ms/step - loss: 1.0023 - accuracy: 0.7168 - val_loss: 1.0956 - val_accuracy: 0.7479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdqLNn6Jm4Kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c933877-7bb0-47b5-adc8-8a83fce9982d"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_ = np.argmax(y_test, axis = 1)\n",
        "\n",
        "print(accuracy_score(y_pred, y_test_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "0.7479131886477463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjpF_q4qhKP-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "64b16366-e0ab-4613-a190-9a570f40bdc5"
      },
      "source": [
        "# Plot history: Categorical crossentropy & Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Categorical crossentropy (training data)')\n",
        "plt.plot(history.history['val_loss'], label='Categorical crossentropy (validation data)')\n",
        "plt.plot(history.history['accuracy'], label='Accuracy (training data)')\n",
        "plt.plot(history.history['val_accuracy'], label='Accuracy (validation data)')\n",
        "plt.title('Model performance for SimpleRNN example')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrIn0oX3h6Nn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}